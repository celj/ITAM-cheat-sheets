% !TEX program = lualatex

\documentclass[8pt,a4paper]{extarticle}
\input{../template_es.tex}
\input{../macros.tex}

% Class info
\renewcommand{\csClass}{Optimización}
\renewcommand{\csClassCode}{MAT - 22211}
\renewcommand{\csTerm}{Primavera 2021}
\renewcommand{\csKeywords}{ }

% PDF Metadata
\hypersetup{
    pdftitle={\csof \csClass},      
    pdfsubject={\csClass},      
    pdfauthor={\csAuthorName},  
    pdfkeywords={}              
}

% Begin document
\begin{document}

\begin{titlepage}
    \begin{center}
	\vspace*{1cm}
	\Huge
        \textbf{\csClass}
	\vspace{0.5cm} \\
	\Large
        \cs\ $\cdot$ \csTerm
        \vfill
        \csAuthorName
	\vspace{0.8cm}
        \csClassCode\\
        \csSchool     
    \end{center}
\end{titlepage}

\begin{multicols}{3}
\setcounter{page}{1}

\section{Optimización estática}

\subsection{Análisis convexo}

\begin{boxdef}[Conjunto convexo]
	Sea $X \subseteq \mathbb{R}^n$, decimos que $X$ es \textbf{convexo} si, para cualesquiera $\mathbf{x}, \mathbf{y} \in X$ y para toda $\lambda \in (0, 1)$, se cumple:
	\[
		\lambda \mathbf{x} + (1 - \lambda)\mathbf{y} \in X
	.\] 
	Equivalentemente, decimos que $X$ es \textbf{convexo} si, para todas $a \in \partial X$ y $b \in X$, existe $\ell$ tal que $\langle b - a, \ell \rangle \le 0$; donde $\partial X$ es la \emph{frontera} de $X$ y $\langle \cdot\, , \cdot \rangle$ denota el producto punto.
\end{boxdef}

\begin{center}
\begin{tikzpicture}
	\begin{scope}
		\draw[rotate=-45,fill=red!30] (0,0) ellipse (45pt and 30pt);
	\node [label={[yshift=-2.2cm]Conjunto convexo}] {};
	\end{scope}
	\begin{scope}[xshift=3.5cm]
		\useasboundingbox (-1,-1.35) rectangle (1.5,1.35);
		\draw[fill=red!30] (0,0) to [out=140,in=90] (-1,-1)
		to [out=-90,in=240] (0.8,-0.6)
		to [out=60,in=-60] (1.2,1.2)
		to [out=120,in=90] (0.3,0.7)
		to [out=-90,in=20] (0.3,0)
		to [out=200,in=-40] (0,0);
		\draw (-0.5,-0.5) -- (0.7,0.7);
		\fill (-0.5,-0.5) circle[radius=1.5pt];
		\fill (0.7,0.7) circle[radius=1.5pt];
		\node [label={[yshift=-2.2cm]Conjunto no convexo}] {};
	\end{scope}
\end{tikzpicture}
\end{center}

\begin{boxprop}
	Sean $A$ y $B$ dos subconjuntos convexos de $\mathbb{R}^n$, entonces:
	\begin{eqlist}
	\item $A \cap B$ es convexo.
	\item $A + B = \{a + b : a \in A,\ b \in B\}$ es convexo.
	\item Para todo $k \in \mathbb{R}$, $kA = \{ka : a\in A\}$ es convexo.
	\end{eqlist}
\end{boxprop}

\begin{boxdef}[Función convexa]
	Sea $X \subseteq R^n$ un conjunto convexo, $f : X \to \mathbb{R}$ es una \textbf{función convexa} si, para toda $\mathbf{x}_1 \neq \mathbf{x}_2 \in X$ y toda $\lambda \in (0, 1)$, se tiene:
	\[
		f(\lambda \mathbf{x}_1 + (1 - \lambda)\mathbf{x}_2) \le \lambda f(\mathbf{x}_1) + (1 - \lambda) f(\mathbf{x}_2)
	.\] 
	Si la desigualdad es estricta, se dice que la función es \textbf{estrictamente convexa}.
\end{boxdef}

\begin{boxdef}[Función cóncava]                                                                                         
    Sea $X \subseteq R^n$ un conjunto convexo, $f : X \to \mathbb{R}$ es una \textbf{función cóncava} si, para toda $\mathbf{x}_1 \neq \mathbf{x}_2 \in X$ y toda $\lambda \in (0, 1)$, se tiene:
    \[                                                                                                                  
        f(\lambda \mathbf{x}_1 + (1 - \lambda)\mathbf{x}_2) \ge \lambda f(\mathbf{x}_1) + (1 - \lambda) f(\mathbf{x}_2)                                     
    .\]                                                                                                                 
    Si la desigualdad es estricta, se dice que la función es \textbf{estrictamente cóncava}.                            
\end{boxdef}

\begin{boxdef}
	Sea $X \subseteq \mathbb{R}^n$ y $f : X \to \mathbb{R}$ una función, definimos:
	\begin{bulletlist}
	\item la \textbf{gráfica} de $f$ como $G_f = \{ (\mathbf{x}, r) \in X \times \mathbb{R} : f(\mathbf{x}) = r \} $.
	\item el \textbf{epígrafo} de $f$ como $E_f = \{ (\mathbf{x}, r) \in X \times \mathbb{R} : f(\mathbf{x}) \le r \}$.
	\item el \textbf{hipógrafo} de $f$ como $H_f = \{ (\mathbf{x}, r) \in X \times \mathbb{R} : f(\mathbf{x}) \ge r \}$.
	\end{bulletlist}
\end{boxdef}

\begin{boxtheo}
	Sea $X \subseteq \mathbb{R}^n$ un conjunto convexo,
	\begin{eqlist}
	\item una función $f : X \to \mathbb{R}$ es convexa si y solo si $E_f$ es un conjunto convexo de $\mathbb{R}^{n+1}$.
	\item una función $f : X \to \mathbb{R}$ es cóncava si y solo si $H_f$ es un conjunto convexo de $\mathbb{R}^{n+1}$.
	\end{eqlist}
\end{boxtheo}

\begin{boxprop}
	Sean $X \subseteq \mathbb{R}^n$ un conjunto convexo, $f : X \to \mathbb{R}$ y $g : X \to \mathbb{R}$ dos funciones cóncavas, y $\alpha \in \mathbb{R}$, entonces:
	\begin{eqlist}
	\item $f$ es cóncava si $\alpha > 0$.
	\item $f$ es convexa si $\alpha < 0$.
	\item $f+g$ es cóncava.
	\end{eqlist}
\end{boxprop}

\begin{boxprop}
	Sean $X \subseteq \mathbb{R}^n$ un conjunto convexo, $g : X \to \mathbb{R}$ una función cóncava, y $h : Y \to \mathbb{R}$ una función cóncava y creciente tal que $g(X) \subseteq Y \subseteq \mathbb{R}$; entonces, $h \circ g$ es cóncava.
\end{boxprop}

\begin{boxdef}[Vector gradiente]
	Sea $f \in \mathcal{C}^1 (X)$, el \textbf{vector gradiente} de $f$ está dado por:
	\[
		\nabla f(\mathbf{x}) =
		\begin{pmatrix} \displaystyle \frac{\partial f}{\partial x_1} \\ \vdots \\ \displaystyle \frac{\partial f}{\partial x_n} \end{pmatrix} 
	.\] 
\end{boxdef}

\begin{boxdef}[Matriz hessiana]
	Sea $f \in \mathcal{C}^2 (X)$, se define la \textbf{matriz hessiana} de $f$ como $H_f(\mathbf{x})$, donde:
	\[
		H_f (\mathbf{x})_{i,j} = \frac{\partial^2 f(\mathbf{x})}{\partial x_i \partial x_j} 
	.\] 
\end{boxdef}

\begin{boxdef}[Serie de Taylor]
	\[
		T(\mathbf{x}) = \sum_{|\alpha| \ge 0} \frac{(\mathbf{x} - \mathbf{a})^\alpha}{\alpha\,!} \left(\partial^\alpha f \right)(\mathbf{a})
	.\] 
\end{boxdef}

\begin{boxtheo}[de Taylor]
	Sea $f : \mathbb{R}^n \to \mathbb{R}$ tal que $f \in \mathcal{C}^k(\mathbf{a})$. Entonces, existe $h_{\alpha} : \mathbb{R}^n \to \mathbb{R}$ tal que:
	\[
		f(\mathbf{x}) = \sum_{|\alpha| \le k} \frac{\partial^\alpha f(\mathbf{a})}{\alpha\,!} (\mathbf{x} - \mathbf{a})^\alpha + \sum_{|\alpha| = k} h_{\alpha}(\mathbf{x})(\mathbf{x} - \mathbf{a})^\alpha
	,\] 
	y
	\[
		\lim_{\mathbf{x} \to \mathbf{a}} h_{\alpha} (\mathbf{x}) = 0
	.\] 
\end{boxtheo}

\begin{boxdef}[Matriz simétrica]
	Decimos que una matriz $A \in \mathcal{M}_{n \times n}$ es \textbf{simétrica} si y solo si:
	\[
	A = A^T
	.\] 
\end{boxdef}

\begin{boxdef}[Matriz diagonalizable]
	Decimos que una matriz $A \in \mathcal{M}_{n \times n}$ es \textbf{diagonalizable} si y solo si existe una matriz $P  \in \mathcal{M}_{n \times n}$ invertible tal que $P^{-1}AP$ es diagonal.
\end{boxdef}

\begin{boxdef}[Matriz ortogonalmente diagonalizable]
	Decimos que una matriz $A \in \mathcal{M}_{n \times n}$ es \textbf{ortogonalmente diagonalizable} si y solo si existe una matriz $T  \in \mathcal{M}_{n \times n}$ invertible tal que $T^{-1}AT$ es diagonal y $T^{-1} = T^T$.
\end{boxdef}

\begin{boxtheo}[]
	Si $A \in \mathcal{M}_{n \times n}$ es simétrica, sus valores propios son reales.
\end{boxtheo}

\begin{boxtheo}[]
	Una matriz simétrica $A$ de tamaño $n \times n$ puede determinar la forma cuadrática $q_A$ de $n$ variables como sigue:
	\[
		q_A (\mathbf{x}) = \sum_{i = 1}^n \sum_{j = 1}^n a_{ij}x_ix_j = \mathbf{x}^T A \mathbf{x}
	.\] 
\end{boxtheo}

\begin{boxcor}[Clasificación de formas cuadráticas]
	La matriz asociada a la forma cuadrática $q_A$ es:
	\begin{eqlist}
	\item definida positiva si $q_A(\mathbf{x}) > 0,\ \forall \mathbf{x} \neq 0$.
	\item definida negativa si $q_A(\mathbf{x}) < 0,\ \forall \mathbf{x} \neq 0$.
	\item semidefinida positiva si $q_A(\mathbf{x}) \ge 0,\ \forall \mathbf{x} \neq 0$.
	\item semidefinida negativa si $q_A(\mathbf{x}) \le 0,\ \forall \mathbf{x} \neq 0$.
	\item indefinida si $q_A(\mathbf{x})$ toma tanto valores positivos como negativos.
	\end{eqlist}
\end{boxcor}

\newpage

\section{Cálculo de variaciones}

\newpage

\section{Teoría de control óptimo}

\newpage

\section{Elementos de programación dinámica}

\vfill\eject
\columnbreak
\end{multicols}
\end{document}
